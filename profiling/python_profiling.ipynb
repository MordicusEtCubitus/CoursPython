{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiler vos programmes avec Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Stop watch](stopwatch.jpg \"Pixabay https://pixabay.com/illustrations/stopwatch-time-treadmill-race-259303/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Les boutons *Solution* empêchent le bon rendu de ce notebook par **github** ou *nbviewer*, vous pouvez utiliser ce lien **[MyBinder](https://mybinder.org/v2/gh/MordicusEtCubitus/CoursPython/master?filepath=profiling%2Fpython_profiling.ipynb)** pour une bonne visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce TP propose des exercices présentant quelques librairies Python permettant de profiler votre code source afin d'essayer d'identifier les sources de ralentissement de vos programmes.\n",
    "\n",
    "En matière de [profilage](https://fr.wikipedia.org/wiki/Profilage_de_code), Python propose plusieurs librairies en standard:\n",
    "\n",
    "* **timeit**  \n",
    "  https://docs.python.org/3/library/timeit.html \n",
    "* **cProfile**  \n",
    "  https://docs.python.org/3/library/profile.html\n",
    "* **Trace**  \n",
    "  https://docs.python.org/3/library/trace.html#module-trace  \n",
    "* **FaultHandler**  \n",
    "  https://docs.python.org/3/library/faulthandler.html\n",
    "  \n",
    "D'autres librairies issues de la communauté sont aussi disponibles, dont:\n",
    "\n",
    "* **[PyCallGraph](http://pycallgraph.slowchop.com/en/master/)** et son fork **[PyCallGraph2](https://github.com/daneads/pycallgraph2#readme#readme)** qu'il est conseillé car la première version n'est plus vraiment maintenue.\n",
    "\n",
    "* **[pyprof2calltree](https://github.com/pwaller/pyprof2calltree/#readme)** qui permet de collecter des traces pStats de *cProfile* pour les visualiser avec *[KCachegrind](https://kcachegrind.github.io/html/Home.html)*\n",
    "\n",
    "* Et nous en verrons quelques autres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types de profiler\n",
    "\n",
    "On dénote en général 2 types de profileurs:\n",
    "\n",
    "* Les profileurs événementiels ou déterministes (*Tracing Profiler*), qui enregistrent toutes les actions qui se passent dans le programme et peuvent fournir beaucoup de statistiques très précises.   \n",
    "Ils présentent l'inconvénient d'être très gourmands en ressources et peuvent ralentir considérablement le programme principal, ce qui les rend parfois inutilisables.\n",
    "\n",
    "* Les profileurs statistiques qui prélèvent à intervalles réguliers des informations sur votre programme.  \n",
    "  Beaucoup moins gourmands en ressources ils ne fournissent pas une vue complète du programme et peuvent manquer des éléments si ceux-ci se produisent en dehors de leurs intervalles de mesure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time It\n",
    "\n",
    "La librairie **timeit** est relativement facile à utiliser: vous lui passez sous forme de texte, le code à exécuter, plus quelques paramètres comme le nombre de fois où ce code doit être lancé ainsi que les variables de départ, et elle exécute votre code pour vous retourner le temps mesuré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un exemple valant mieux qu'un long discours, essayons avec la [suite de Padovan](https://fr.wikipedia.org/wiki/Suite_de_Padovan) en version récursive, histoire de ne pas reprendre l'exemple plus classique qu'est Fibonacci !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "def padovan(n):\n",
    "    # assert n >= 0\n",
    "    \n",
    "    if n <= 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return padovan(n - 2) + padovan(n - 3)\n",
    "    \n",
    "for n, value in enumerate((1, 1, 1, 2, 2, 3, 4, 5, 7, 9, 12)):\n",
    "    assert padovan(n) == value\n",
    "    \n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeit.timeit(stmt=\"padovan(20)\") # Erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "timeit.timeit(stmt=\"padovan(20)\") # Erreur\n",
    "```\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "<ipython-input-132-6cd060fb81bb> in <module>\n",
    "----> 1 timeit.timeit(stmt=\"padovan(20)\") # Erreur\n",
    "\n",
    "~/anaconda/lib/python3.7/timeit.py in timeit(stmt, setup, timer, number, globals)\n",
    "    230            number=default_number, globals=None):\n",
    "    231     \"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\n",
    "--> 232     return Timer(stmt, setup, timer, globals).timeit(number)\n",
    "    233 \n",
    "    234 def repeat(stmt=\"pass\", setup=\"pass\", timer=default_timer,\n",
    "\n",
    "~/anaconda/lib/python3.7/timeit.py in timeit(self, number)\n",
    "    174         gc.disable()\n",
    "    175         try:\n",
    "--> 176             timing = self.inner(it, self.timer)\n",
    "    177         finally:\n",
    "    178             if gcold:\n",
    "\n",
    "~/anaconda/lib/python3.7/timeit.py in inner(_it, _timer)\n",
    "\n",
    "NameError: name 'padovan' is not defined\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction **timeit** ne connaît pas les fonctions de votre programme, il convient de les lui transmettre via le paramètre *globals*. Ce paramètre attend un dictionnaire dont les clefs sont les noms de vos objets.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.96059255599903"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(stmt=\"padovan(20)\", globals={'padovan' : padovan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce temps peut sembler bien long, en effet, **timeit** exécute par défaut un million de fois le code demandé. Et retourne le temps total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-688ca614799b>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-688ca614799b>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print( f\"Durée moyenne en secondes: {total_time/repeat:08.06f}\")\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "repeat = 100000\n",
    "total_time = timeit.timeit(stmt=\"padovan(20)\", number=repeat, globals=globals())\n",
    "print(\"Durée totale en secondes pour %s exécutions : %08.06f\" % (repeat, total_time))\n",
    "print( f\"Durée moyenne en secondes: {total_time/repeat:08.06f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB** : Dans l'exemple ci-dessus nous utilisons la fonction python `[globals](https://docs.python.org/3.7/library/functions.html#globals)` qui retourne le dictionnaire des objets globaux pour initialiser le paramètre de **timeit** du même nom, c'est bien plus pratique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le temps moyen n'est pas forcément un bon critère: lors de multiples exécutions la durée peut varier d'une fois à l'autre de manière significative selon la charge de votre système, surtout sur de petits délais comme celui-ci.\n",
    "\n",
    "Dans ce cas la fonction `repeat`, qui répète plusieurs fois les `number` mesures et pour chaque répétition retourne le meilleur temps de ces mesures peut s'avérer être une meilleure option en ne conservant que la valeur minimale de la liste résultat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = timeit.repeat(stmt=\"padovan(20)\", globals=globals(), repeat=10, number=100)\n",
    "print(\"Meilleurs temps des 10 séries de 100 mesures: \")\n",
    "print(times)\n",
    "print(\"\\nMeilleur temps pour les 100 mesures:\", min(times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, chaque mesure reste un temps cumulé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pourquoi de nombreux exemples de profiling utilisent des suites numériques à double récursivité ?  \n",
    "\n",
    "Parce que leur code est très consommateur de temps : chaque appel lance 2 autres appels, qui à leur tour en lancent 2 autres, et ainsi de suite. Pour calculer padovan(7), 8 appels de sous fonctions sont réalisés.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\"\"\"\n",
    "Pour installer graphviz :\n",
    "\n",
    "bash$ pip install graphviz\n",
    "\n",
    "ou\n",
    "\n",
    "bash$ conda install graphviz\n",
    "\n",
    "Vérifiez que le programme 'dot' est dans votre path\n",
    "\n",
    "bash$ which dot\n",
    "/home/user/anaconda/bin/dot\n",
    "\n",
    "Sous Windows ou Mac vous pourriez avoir besoin d'installer directement le binaire du logiciel\n",
    "Vous le trouverez à cette adresse : http://graphviz.org/download/\n",
    "\n",
    "Sous Windows, vérifiez que dot.exe est dans votre path\n",
    "\n",
    "C:> set PATH=%PATH%;c:/path/to/dot.exe\n",
    "\"\"\"\n",
    "\n",
    "dot = Digraph(comment='Padovan Tree', format='svg')\n",
    "\n",
    "def pado(n, g, node_name=None):\n",
    "    \n",
    "    if not node_name:\n",
    "        node_name = \"1\"\n",
    "        label = \"%s - pado(%s)\" % (node_name, n)\n",
    "        g.node(node_name, label)\n",
    "    \n",
    "    \n",
    "    if n > 2:\n",
    "        s1 = node_name + \".1\"\n",
    "        s2 = node_name + \".2\"\n",
    "\n",
    "        label = \"%s - pado(%s)\" % (s1, n - 2)\n",
    "        g.node(s1, label)\n",
    "\n",
    "        label = \"%s - pado(%s)\" % (s2, n - 3)\n",
    "        g.node(s2, label)\n",
    "        g.edge(node_name, s1)\n",
    "        g.edge(node_name, s2)\n",
    "\n",
    "    return 1 if n <= 2 else pado(n - 2, g, node_name=s1) + pado(n - 3, g, node_name=s2)\n",
    "\n",
    "pado(7, dot)\n",
    "dot  # dot.view()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'ordre de grandeur du nombre d'appels imbriqués pour `padovan(n)` est `2**(n-1)`.  \n",
    "Cette implémentation utilisant une double récursivité est particulièrement mauvaise du point de vue des performances puisqu'elle génère des temps de calculs exponentiels.\n",
    "\n",
    "Juste pour le plaisir, voici une autre manière un peu plus générique de générer le graphe des appels en utilisant les modules **traceback** et **inspect** de Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import inspect \n",
    "\n",
    "def pado(n, first=True):\n",
    "    \n",
    "    # Current frame\n",
    "    cf = inspect.currentframe()\n",
    "    \n",
    "    # Traceback parent frame, Traceback current frame\n",
    "    tb_pf, tb_cf = traceback.extract_stack(cf, limit=2)\n",
    "    \n",
    "    pf = cf.f_back\n",
    "    \n",
    "    if first:\n",
    "        pado.graph = Digraph(format=\"svg\")\n",
    "        \n",
    "    # Ici nous avons de la chance, l'identifiant de la frame current n'est pas réutilisé une fois que la fonction existe\n",
    "    # Ainsi, 2 appels distincts ont un identifiant de trame unique et le graphique est correctement construit\n",
    "    # Mais je ne comprends pas vraiment pourquoi ça marche bien ici et les ids ne sont pas réutilisés. \n",
    "    # S'il était réutilisé, le graphique serait gravement cassé.\n",
    "    pado.graph.node(str(id(cf)), \"%s(%s)\" % (tb_cf.name, n))\n",
    "    \n",
    "    if not first:\n",
    "        pado.graph.edge(str(id(pf)), str(id(cf)))\n",
    "        \n",
    "    return 1 if n <= 2 else pado(n - 3, False) + pado(n - 2, False)\n",
    "\n",
    "pado(7)\n",
    "\n",
    "pado.graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela reste un brin laborieux, nous verrons que l'on peut faire beaucoup plus générique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisons l'évolution du graphique.  Selon votre processeur, cela peut demander quelques secondes, voire minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "times = [] \n",
    "data = range(0, 64, 2)\n",
    "\n",
    "for n in data:\n",
    "    t = timeit.timeit(stmt=\"padovan(n)\", globals=globals(), number=1)\n",
    "    times.append(t)\n",
    "\n",
    "    \n",
    "plt.plot(data, times, label=\"padovan(n)\")\n",
    "\n",
    "# Est-ce réellement exponentiel?\n",
    "average_by_call = times[-1] / 2**61\n",
    "plt.plot(data, [(2**(n-1)*average_by_call) for n in data], label=\"2**(n-1) * (average time)\")\n",
    "\n",
    "plt.xlabel(\"Values of n\")\n",
    "plt.ylabel(\"Duration in seconds\")\n",
    "plt.xticks(data)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice\n",
    "\n",
    "\n",
    "Le [jour de dépassement](https://fr.wikipedia.org/wiki/Jour_du_d%C3%A9passement) (*Earth Overshoot Day* ou EOD) est cette année 2019, le 29 juillet.\n",
    "\n",
    "Nous savons que les Data Centers du monde entier consomment 10% de la production électrique mondiale.\n",
    "\n",
    "Si la consommation électrique était proportionnelle à la durée d'exécution d'un programme - ce qui est une assertion loin d'être exacte - en parallélisant à outrance nous pourrions économiser beaucoup de ressources.\n",
    "\n",
    "Mesurer avec **timeit** le temps de téléchargement en série ou en \"parallèle\" avec des threads des URL suivantes:\n",
    "\n",
    "* https://fr.wikipedia.org/wiki/Jour_du_d%C3%A9passement  \n",
    "* https://www.franceculture.fr/emissions/le-choix-de-la-redaction-13-14/data-centers-les-ogres-energivores-dinternet  \n",
    "* https://www.connaissancedesenergies.org/sites/default/files/pdf-actualites/guide-pratique-internet-courriels-reduire-impacts.pdf\n",
    "\n",
    "Dans cet exemple, le programme prendra peut-être trois fois moins de temps pour le téléchargement total, mais 3 processeurs/coeurs fonctionneront au lieu d'un seul, la consommation électrique risque donc d'être 3 fois supérieure sur ce temps réduit.\n",
    "\n",
    "Vous pouvez utiliser la librairie **[requests](https://3.python-requests.org/)** pour télécharger simplement les URL:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "r = requests.get('https://3.python-requests.org')\n",
    "```\n",
    "\n",
    "Dans l'exercice, commencez par utiliser *http://www.python.org* à la place du fichier PDF, puis utilisez le fichier PDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread, mode d'emploi\n",
    "from threading import Thread\n",
    "\n",
    "def square(x):\n",
    "    return x**2\n",
    "\n",
    "# Création du thread\n",
    "t = Thread(target=square, args=(10,))\n",
    "\n",
    "# Démarrage du thread (la fonction s'éxécute parallèlement au code principal)\n",
    "t.start()\n",
    "\n",
    "# Attente de la fin d'exécution du thread\n",
    "t.join()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from threading import Thread\n",
    "import timeit\n",
    "\n",
    "urls = ['https://fr.wikipedia.org/wiki/Jour_du_d%C3%A9passement'\n",
    "        , 'https://www.franceculture.fr/emissions/le-choix-de-la-redaction-13-14/data-centers-les-ogres-energivores-dinternet'\n",
    "        , 'https://www.python.org']  # Dans l'exercice, commencez par utiliser python.org à la place du fichier PDF, puis utilisez le fichier PDF.\n",
    "\n",
    "# <votre code ici>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#timeit1\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"timeit1\" class=\"collapse\">\n",
    "\n",
    "```python\n",
    "\n",
    "def download_serial(urls):\n",
    "    for url in urls:\n",
    "        r = requests.get(url)\n",
    "        \n",
    "def download_thread(urls):\n",
    "    tasks = []\n",
    "    \n",
    "    for url in urls:\n",
    "        t = Thread(target=requests.get, args=(url,))\n",
    "        t.start()  # démarrage du thread\n",
    "        # Ne pas join() directement ici sinon l'exécution se fera en série, or\n",
    "        # join() est un processus bloquant pour la suite du programme\n",
    "        tasks.append(t)  # nous conservons une référence menant au thread\n",
    "            \n",
    "    for t in tasks:\n",
    "        t.join()  # attente de la fin d'exécution du thread\n",
    "        \n",
    "        \n",
    "r1 = timeit.timeit(stmt=\"download_serial(urls)\", globals=globals(), number=1)\n",
    "r2 = timeit.timeit(stmt=\"download_thread(urls)\", globals=globals(), number=1)\n",
    "\n",
    "print(\"Time using serial download %s seconds\" % r1)\n",
    "print(\"Time using thread download %s seconds\" % r2)\n",
    "print(\"Thread versus Serial: x%s\" % (r1 / r2))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter %timeit\n",
    "\n",
    "Les notebooks **jupyter** ont aussi un mot clef magique `%timeit` basé sur la librairie python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit padovan(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le mot clef accepte aussi des paramètres:\n",
    "\n",
    "* `-r` : nombre de répétitions/séries de mesures\n",
    "* `-n` : nombre de mesures par série\n",
    "\n",
    "Les opérations sont exécutées dans une autre frame, vos variables ne sont pas forcément modifiées après coup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -r 1 -n 1 padovan(36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, ici, la variable `r` ne contiendra pas la dernière valeur calculée, car dans l'autre frame/bloc, une variable `r` locale est créée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10\n",
    "r = 5\n",
    "\n",
    "%timeit r = a * 2\n",
    "\n",
    "print( r )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alors qu'ici le code modifie une variable existante, sans qu'il y ait affectation, donc création d'une variable locale à la frame.  Dans ce cas la variable `a` sera modifiée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [10]\n",
    "\n",
    "%timeit -r 1 -n 3 a.append(10)\n",
    "\n",
    "print( a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le mot clef existe aussi en version longue pour chronométrer le temps d'exécution d'une cellule.\n",
    "Voici un exemple avec un algorithme d'intersection très peu efficace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    inter = []\n",
    "\n",
    "    for e1 in l1:\n",
    "        for e2 in l2:\n",
    "            if e1 == e2:\n",
    "                inter.append(l1)\n",
    "\n",
    "    return inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = range(2000)\n",
    "b = range(1000, 3000)\n",
    "intersection(a, b)\n",
    "# N'exécutez pas print dans une cellule contenant %%timeit\n",
    "# car print va s'exécuter tant de fois que vous pourriez avoir besoin de redémarrer votre machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayez de multiplier par 10 le nombre d'éléments des listes `l1` et `l2`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter %time\n",
    "\n",
    "Le mot clef magique `%time` se comporte comme la commande `time` Unix: Il mesure le temps d'exécution de votre commande et affiche 3 temps : système, utilisateur et réel.\n",
    "\n",
    "Il n'exécute qu'une seule fois la commande."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10\n",
    "%time a = a+ 1\n",
    "print(a)\n",
    "b = []\n",
    "%time b.append(4)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il peut aussi s'appliquer sur une cellule entière:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "r = padovan(36)\n",
    "print(\"padovan(36) is\", r)\n",
    "\n",
    "intersection(range(10000), range(5000,15000))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cProfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cProfile** (basée sur l'ancienne librairie **lsprof**) est elle aussi disponible en standard avec Python.  Cette librairie permet de profiler tout ou partie de votre code et génère des statistiques sur les fonctions, comme leur nombre d'appels ou leur temps d'exécution.  \n",
    "Elle ne permet cependant pas de mesurer l'usage de la mémoire.\n",
    "\n",
    "**cProfile** propose un profileur déterministe/événementiel. Mais il reste tout à fait utilisable car la conception de Python fournit déjà toute la mécanique nécessaire pour intercepter tous les appels de fonctions et autres objets. De ce fait l'implémentation de tels profileurs est simple et reste modérément gourmande en ressources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie possède une fonction `run` qui exécute comme **timeit** le code passé sous forme de chaîne de caractères. Mais dans ce cas, il n'est pas nécessaire de fournir le dictionnaire des objets globaux nécessaires à l'exécution de la fonction.\n",
    "\n",
    "Le résultat peut être visualisé sous forme de tableau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "cProfile.run(\"padovan(39)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres ont la signification suivante:\n",
    "\n",
    "* `ncalls` : Le nombre d'appels. Si 2 nombres sont présents cela signifie que la fonction est récursive. Le premier nombre correspond au nombre total d'appels, le second correspond au nombre d'appels de premiers niveau\n",
    "* `tottime` : La durée totale d'exécution de la fonction, excluant les appels de sous-fonctions\n",
    "* `percall` : La durée moyenne: correspond à *ncalls / tottime*\n",
    "* `cumtime` : Le temps cumulé de la fonction et de toutes ses sous fonctions\n",
    "* `percall` : Le temps moyen cumulé (appels de premier niveau): Correspond à *cumtime / ncalls*\n",
    "* `filename:lineno(function)` : comme indiqué: nom de fichier, ligne et nom de fonction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais mesurer le temps d'exécution d'un programme en utilisant des chaînes de caractères n'est pas vraiement exploitable pour analyser l'ensemble d'un programme.\n",
    "\n",
    "Pour cela la librairie permet d'analyser une partie de votre code en instanciant un objet de la classe `Profile` puis en appelant ses méthodes `enable` et `disable`  \n",
    "\n",
    "L'intégralité du code compris entre ces méthodes sera monitoré:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def countdown(x):\n",
    "    assert x > 0\n",
    "    \n",
    "    while x > 0:\n",
    "        x -= 1\n",
    "\n",
    "def cube(x):\n",
    "    return x ** 3\n",
    "\n",
    "pr = cProfile.Profile()  # Création du profiler\n",
    "pr.enable()  # Activation du profiler\n",
    "\n",
    "padovan(20)  # est profilé\n",
    "for x in range(1000, 100000, 1000):\n",
    "    countdown(x)  # est profilé\n",
    "\n",
    "    \n",
    "a = range(2000)\n",
    "b = range(1000, 3000)\n",
    "\n",
    "intersection(a, b)\n",
    "    \n",
    "pr.disable()  # Désactivation du profiler\n",
    "\n",
    "cube(10)  # n'est pas profilé\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode `print_stats` permet quant à elle d'afficher les statistiques. Il est aussi possible de les sauvegarder dans un fichier avec `dump_stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.print_stats(sort='cumulative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, la classe [`Stats`](https://docs.python.org/3/library/profile.html#module-pstats) permet de personnaliser l'affichage et le calcul des statistiques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile, pstats, io\n",
    "\n",
    "pr = cProfile.Profile()\n",
    "pr.enable()\n",
    "\n",
    "# ... fantastique code ...\n",
    "padovan(20)\n",
    "countdown(10**6)\n",
    "\n",
    "pr.disable()\n",
    "\n",
    "s = io.StringIO()\n",
    "\n",
    "ps = pstats.Stats(pr, stream=s)\n",
    "ps.strip_dirs()  # supprime le nom complet du chemin d'accès au fichier/à la fonction\n",
    "ps.sort_stats('cumtime')  # trier par temps cumulé décroissant\n",
    "ps.print_stats()\n",
    "\n",
    "print(s.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter prun et lprun\n",
    "\n",
    "Jupyter propose 2 autres mots clefs magiques permettant de profiler votre code:\n",
    "\n",
    "* *%prun*: Semblable à `%run -p`, cette commande exécute le code en activant le profiler cProfile\n",
    "* *%lprun*: Mesure le temps d'exécution de chaque ligne de code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun -s calls intersection(range(1000,2000), range(2000, 3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = %prun -r -s calls padovan(5)\n",
    "ps.strip_dirs()  # ps.strip_dirs()  # supprime le nom complet du chemin d'accès au fichier/à la fonction\n",
    "ps.sort_stats('cumtime')  #trier par temps cumulé décroissant\n",
    "ps.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le mot clef magique *%lprun* n'est pas fourni en standard. C'est un plugin de la librairie **[line profiler](https://github.com/rkern/line_profiler)**\n",
    "\n",
    "Il convient d'installer la librairie puis de charger l'extension dans **Jupyter**\n",
    "\n",
    "```bash\n",
    "bash ou C:> pip install line_profiler\n",
    "```\n",
    "\n",
    "Ensuite il reste à charger l'extension dans **Jupyter**:\n",
    "\n",
    "`%load_ext line_profiler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il convient d'indiquer quelles sont les fonctions que l'on souhaite analyser dans la commande saisie...  \n",
    "Ce qui peut paraître déroutant quand il n'y en a qu'une, mais cette option permet de ne profiler que des sous-fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f intersection intersection(range(1000), range(500,1500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 0.423649 s\n",
    "File: <ipython-input-19-a73c801d2e85>\n",
    "Function: intersection at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           def intersection(l1, l2):\n",
    "     2         1          3.0      3.0      0.0      inter = []\n",
    "     3                                           \n",
    "     4      1001        199.0      0.2      0.0      for e1 in l1:\n",
    "     5   1001000     209590.0      0.2     49.5          for e2 in l2:\n",
    "     6   1000000     213710.0      0.2     50.4              if e1 == e2:\n",
    "     7       500        146.0      0.3      0.0                  inter.append(l1)\n",
    "     8                                           \n",
    "     9         1          1.0      1.0      0.0      return inter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commençons à entrevoir la cause des temps relativement élevés de la fonction `intersection` : le test *if* est exécuté 1 million de fois dans cet exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définir votre propre profiler\n",
    "\n",
    "Le module **sys** possède une chouette fonction [`setprofile`](https://docs.python.org/3/library/sys.html#sys.setprofile) qui vous permet de définir une fonction qui sera automatiquement appelée dès que certains événements se produiront, comme:\n",
    "\n",
    "* `call` : L'exécution d'une fonction\n",
    "* `return` : Le retour d'une fonction\n",
    "* autres...\n",
    "\n",
    "La fonction d'analyse de code recevra 3 paramètres:\n",
    "\n",
    "* `frame` : La frame qui va être exécutée\n",
    "* `event` : le nom de l'évènement, cf ci-dessus\n",
    "* `arg` : dépend du type de l'évènement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici un petit exemple qui ne sera pas exécuté au travers de jupyter car ce dernier génère beaucoup trop d'appels de fonctions lorsqu'il exécute une cellule et cela va perturber la trace attendue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file my_profiler_example.py\n",
    "# Exemple \n",
    "import sys\n",
    "old_profiler = sys.getprofile()\n",
    "\n",
    "def my_profiler(frame, event, arg):\n",
    "    print(f\"frame={frame}, event={event}, arg={type(arg)}\")\n",
    "    \n",
    "    \n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "a = list(range(10))\n",
    "b = list(range(5,15))\n",
    "\n",
    "# Réglage du profileur\n",
    "sys.setprofile(my_profiler)\n",
    "\n",
    "square(10)\n",
    "\n",
    "# Restauration du profileur précédent\n",
    "sys.setprofile(old_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python my_profiler_example.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre fonction de supervision est appelée 3 fois:\n",
    "\n",
    "* Au démarrage de square\n",
    "* Au moment du return de square\n",
    "* Au début de `sys.setprofile`\n",
    "\n",
    "Grâce à cette fonction et aux modules d'instrospection de Python, il devient possible de créer ses propres sondes de monitoring de code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice relativement difficile\n",
    "En vous inpirant de la seconde version du code générant le graphe de la suite de Padovan, créer une fonction d'analyse générique qui crée le graphe d'appel des fonctions exécutées entre les 2 instructions `sys.setprofile` ci-dessus.\n",
    "\n",
    "Il vous sera beaucoup plus facile de définir cette fonction d'analyse comme une méthode de classe, ce qui permettra de manipuler le graphe et les autres paramètres dont vous pourriez avoir besoin comme attributs des instances de la classe.\n",
    "\n",
    "*Nec plus ultra*: Implémenter les méthodes spéciales de python `__enter__` et `__exit__` qui permettront d'utiliser votre profiler de cette manière:\n",
    "\n",
    "```python\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "def pado(n):\n",
    "    return 1 if n <= 2 else pado(n-3) + pado(n-2)\n",
    "\n",
    "with GraphMe() as gfx:\n",
    "    pado(6)\n",
    "    pado(4)\n",
    "    square(3)\n",
    "    \n",
    "gfx.show()\n",
    "```\n",
    "\n",
    "![Graph me 3](graphme_3.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous ne connaissez pas les context manager, introduits par la [PEP343](https://www.python.org/dev/peps/pep-0343/), voici une présentation de leur fonctionnement:\n",
    "\n",
    "Quand vous écrivez:\n",
    "\n",
    "```python\n",
    "    with MyObject() as var:\n",
    "        actions()\n",
    "```\n",
    "\n",
    "Python exécute quelque chose qui ressemble à:\n",
    "```python\n",
    "    try:\n",
    "        var = MyObject().__enter__()\n",
    "        actions()\n",
    "    finally:\n",
    "        var.__exit__()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui permet de réaliser de belles choses comme cet exemple [très inspiré d'une autre version trouvée sur **stackoverflow**](https://stackoverflow.com/questions/16571150/how-to-capture-stdout-output-from-a-python-function-call):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "class CaptureOutput:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.old_stdout = None\n",
    "        self.new_stdout = None\n",
    "\n",
    "    def __enter__(self):\n",
    "        # Remplace sys.stdout par un fichier en mémoire\n",
    "        self.old_stdout = sys.stdout\n",
    "        self.new_stdout = StringIO()\n",
    "        sys.stdout = self.new_stdout\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        # restauration du fichier sys.stdout précédent\n",
    "        sys.stdout = self.old_stdout\n",
    "\n",
    "    def get(self):\n",
    "        return self.new_stdout.getvalue()\n",
    "\n",
    "\n",
    "print(\"Démarrage...\")\n",
    "\n",
    "with CaptureOutput() as co:\n",
    "    print(\"Un\")\n",
    "    print(\"Deux\")\n",
    "    print(\"Trois\")\n",
    "\n",
    "print(\"Extinction...\")\n",
    "\n",
    "print(\"Texte capturé:\")\n",
    "print(co.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#my_profiler1\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"my_profiler1\" class=\"collapse\">\n",
    "\n",
    "```python\n",
    "\n",
    "\"\"\"\n",
    "La classe GraphMe est un gestionnaire de contexte permettant de générer le graphique d'appel des fonctions.\n",
    "C'est une implémentation très basique utilisée dans le but de démontrer le potentiel de Python/inspection.\n",
    "\n",
    "\n",
    "    from graphme import GraphMe\n",
    "\n",
    "    def fibo(n):\n",
    "        return n if n <= 1 else fibo(n-1) + fibo(n-2)\n",
    "\n",
    "    with GraphMe() as gfx:\n",
    "        fibo(7)\n",
    "\n",
    "    gfx.show()\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import traceback\n",
    "from graphviz import Digraph\n",
    "import inspect\n",
    "\n",
    "class GraphMe:\n",
    "    \"\"\"\n",
    "    GrapĥMe context manager\n",
    "\n",
    "    Lorsque vous écrivez:\n",
    "\n",
    "    with MyObject() as var:\n",
    "        actions()\n",
    "\n",
    "    Python exécute quelque chose comme:\n",
    "\n",
    "    try:\n",
    "        var = MyObject().__enter__()\n",
    "        actions()\n",
    "    finally:\n",
    "        var.__exit__()\n",
    "\n",
    "    C'est ce qu'on appelle le Gestionnaire de Contexte, voir PEP343 pour plus de détails.\n",
    "    https://www.python.org/dev/peps/pep-0343/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename='graphme', format='svg'):\n",
    "        self.old_profile = None  # Garde la trace du profileur précédent, s'il y en a un.\n",
    "        self.graph = None  # objet graphviz\n",
    "        self.call_number = 0  # nombre de fonctions appelées\n",
    "        self.frame_ids = {}  # garde la trace des identifiants des fonctions \n",
    "                             # pour gérer les identifiants uniques et le lien parent\n",
    "        self.filename = filename\n",
    "        self.format = format\n",
    "\n",
    "    def __enter__(self):\n",
    "\n",
    "        self.old_profile = sys.getprofile()  # Conserver le profiler pour le restaurer, s'il y en a déjà un.\n",
    "\n",
    "        # Construit le graphique\n",
    "        self.graph = Digraph(filename=self.filename, format=self.format)\n",
    "\n",
    "        # Réinitialise les valeurs\n",
    "        self.call_number = 0\n",
    "        self.frame_ids = {}\n",
    "\n",
    "        # Définit la fonction utilisée pour construire le graphique\n",
    "        sys.setprofile(self.caller)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.setprofile(self.old_profile)\n",
    "\n",
    "\n",
    "    def caller(self, frame, event, arg):\n",
    "\n",
    "        # Seul le souci de créer des graphiques est pris en compte\n",
    "        if event != 'call':\n",
    "            return\n",
    "\n",
    "        # L'id visant à identifier les fonctions\n",
    "        self.call_number += 1\n",
    "\n",
    "        # Impossible d'utiliser les identificateurs de trame pour identifier de façon unique les appels de fonctions.\n",
    "        # Car lorsqu'une fonction se termine, son identifiant de trame peut être réutilisé pour de nouvelles fonctions.\n",
    "        # Ce qui générerait un graphique erroné, donc nous utilisons un identifiant personnalisé\n",
    "\n",
    "        # Si id existe déjà, il s'agit d'une version réutilisée, nous pouvons l'écraser sans problème\n",
    "        key = id(frame)\n",
    "        self.frame_ids[key] = str(self.call_number)\n",
    "\n",
    "        # Création d'un id de trame et d'un id de trame parent\n",
    "        frame_id = self.frame_ids[key]\n",
    "        parent_frame = frame.f_back\n",
    "        p_key = id(parent_frame)\n",
    "\n",
    "        # If not found, it has not been called inside the with statement, it is the __enter__ statement\n",
    "        if p_key not in self.frame_ids:\n",
    "            self.frame_ids[p_key] = None\n",
    "\n",
    "        parent_frame_id = self.frame_ids[p_key]\n",
    "\n",
    "        # Parent and current traceback frame information: they contain the functions names\n",
    "        tb_parent_frame, tb_frame = traceback.extract_stack(frame, limit=2)\n",
    "\n",
    "        attrs = \", \".join([ \"%s=%s\" % (k, v if type(v) in (int, float, str, bool) else '...') for k, v in frame.f_locals.items()])\n",
    "\n",
    "        # Do not graph __exit__\n",
    "        if self not in frame.f_locals.values():\n",
    "            self.graph.node(frame_id, \"%s(%s)\" % (tb_frame.name, attrs))\n",
    "\n",
    "        # Ne pas ajoutez de lien vers le parent si ce dernier n'est pas créé dans l'instruction\n",
    "        if parent_frame_id is not None:\n",
    "            self.graph.edge(parent_frame_id, frame_id)\n",
    "\n",
    "\n",
    "    def show(self):\n",
    "        self.graph.view()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphme import GraphMe\n",
    "\n",
    "def square(x):\n",
    "    return x ** 3\n",
    "\n",
    "def pado(n):\n",
    "    return 1 if n <= 2 else pado(n-3) + pado(n-2)\n",
    "\n",
    "with GraphMe() as gfx:\n",
    "    pado(6)\n",
    "    pado(4)\n",
    "    square(3)\n",
    "\n",
    "gfx.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous possèdons une jolie classe, amusons-nous un peu..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    return 1 if n <= 1 else n * factorial(n - 1)\n",
    "\n",
    "with GraphMe() as gfx:\n",
    "    factorial(3)\n",
    "\n",
    "gfx.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Factorial](graphme_factorial3.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionParenthesee:\n",
    "    \n",
    "    def __init__(self, texte):\n",
    "        self.texte = texte\n",
    "        self.curseur = 0\n",
    "        \n",
    "    def expression(self):\n",
    "        \"\"\"Retourne True si l'expression est valide, sinon False\"\"\"\n",
    "        r = self.parenthese_ouvrante() \n",
    "        r = r and self.espaces() and self.operande()\n",
    "        r = r and self.espaces() and self.operateur() \n",
    "        r = r and self.espaces() and self.operande()\n",
    "        r = r and self.parenthese_fermante()\n",
    "        \n",
    "        return r\n",
    "    \n",
    "    def courant(self):\n",
    "        \"\"\"Retourne le caractère courant\"\"\"\n",
    "        return self.texte[self.curseur]\n",
    "    \n",
    "    def avance(self):\n",
    "        self.curseur += 1\n",
    "    \n",
    "    def parenthese_ouvrante(self):\n",
    "        if self.courant() == '(':\n",
    "            self.avance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def espaces(self):\n",
    "        \"\"\"Toujours vrai:  ou plusieurs espaces\"\"\"\n",
    "        while self.courant() in ('\\t', ' '):\n",
    "            self.avance()\n",
    "        return True\n",
    "        \n",
    "    \n",
    "    def operande(self):\n",
    "        return self.nombre() or self.expression()\n",
    "        \n",
    "    def operateur(self):\n",
    "        \n",
    "        if self.courant() in \"+-*/\":\n",
    "            self.avance()\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def nombre(self):\n",
    "        \n",
    "        if self.courant() not in \"0123456789\":\n",
    "            return False\n",
    "        \n",
    "        while self.courant() in \"0123456789\":\n",
    "            self.avance()\n",
    "            \n",
    "        return True\n",
    "  \n",
    "    def parenthese_fermante(self):\n",
    "        if self.courant() == ')':\n",
    "            self.avance()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def is_valid(self):\n",
    "        try:\n",
    "            r = self.expression()\n",
    "\n",
    "            if self.curseur != len(self.texte):\n",
    "                # Le début est valide, mais il y a du texte après\n",
    "                return False\n",
    "        except IndexError:\n",
    "            return False\n",
    "        \n",
    "        return r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ExpressionParenthesee(\"(5 + (4*3))\")\n",
    "with GraphMe(filename=\"expression\") as gfx:\n",
    "    e.is_valid()\n",
    "    \n",
    "gfx.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![expression](expr.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela devient vite illisible..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pycallgraph2\n",
    "\n",
    "Vous pouvez être très content de vous si vous avez réussi le \"petit\" exercice précédent...\n",
    "\n",
    "Après cela vous pouvez vous demander : *Mais n'est-il pas possible de faire plus simple ?*  Il n'y a-t-il pas des librairies déjà toutes prêtes pour cela ?\n",
    "\n",
    "La réponse est oui. **PyCallGraph** est une librairie permettant de réaliser automatiquement ce type de graphiques:\n",
    "\n",
    "\n",
    "```bash\n",
    "bash$ pip install pycallgraph2\n",
    "\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycallgraph2 import PyCallGraph\n",
    "from pycallgraph2.output import GraphvizOutput\n",
    "\n",
    "def padovan(n):\n",
    "    return 1 if n <= 2 else pado(n-3) + pado(n-2)\n",
    "\n",
    "gfx = GraphvizOutput()\n",
    "gfx.output_file = 'pycallgraph_padovan.png'\n",
    "\n",
    "with PyCallGraph(output=gfx):\n",
    "    padovan(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Graphe](pycallgraph_padovan.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfx = GraphvizOutput()\n",
    "gfx.output_file = 'pycallgraph_expr.png'\n",
    "\n",
    "e = ExpressionParenthesee(\"(5 + (4*3))\")\n",
    "\n",
    "with PyCallGraph(output=gfx):\n",
    "    e.is_valid()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Graphe](pycallgraph_expr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KCachegrind et pyprof2calltree\n",
    "\n",
    "[**KCachegrind**](https://kcachegrind.github.io) est un outil de la suite **KDE** permettant de visualiser des données de profilage issues de différents formats.\n",
    "\n",
    "![**KCachegrind**](https://kcachegrind.github.io/images/KcgShot3.gif)\n",
    "\n",
    "[pyprof2calltree](https://github.com/pwaller/pyprof2calltree#readme) est une librairie Python qui génère des statistiques de types *pStat*, qu'il est ensuite possible d'afficher avec **KCachegrind**\n",
    "\n",
    "\n",
    "Il convient d'abord d'installer ces logiciels:\n",
    "\n",
    "```bash\n",
    "bash$ sudo apt install kcachegrind\n",
    "\n",
    "bash$ pip install pyprof2calltree\n",
    "```\n",
    "\n",
    "Ensuite vous lancez le profiling de votre programme avec **pyprof2calltree** et vous consultez les statistiques générées avec **kcachegrind**\n",
    "\n",
    "Reprenons l'exemple avec l'analyseur d'expressions bien parenthèsées utilisé lors de l'exercice **GraphMe**. Il possède un sympathique graphe d'exécution qui sera plus démonstratif que les fonctions padovan ou intersection précédemment manipulées.\n",
    "\n",
    "Sous Windows vous devriez pouvoir installer [**qcachegrind**](https://sourceforge.net/projects/qcachegrindwin/) à la place de **Kcachegrind**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import Profile\n",
    "from pyprof2calltree import convert, visualize\n",
    "\n",
    "pr = Profile()\n",
    "pr.enable()\n",
    "\n",
    "e = ExpressionParenthesee(\"(5 + (4*3))\")\n",
    "print(e.is_valid())\n",
    "\n",
    "pr.disable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant générer les statistiques *pStats* pour les afficher avec *kcachegrind*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pr.getstats()\n",
    "visualize(stats) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](kcachegrind_expression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La liste de gauche vous permet de visualiser la liste des fonctions appelées et leur temps d'exécution\n",
    "* Les onglets en haut à droite vous permettent de visualiser la carte des fonctions appelées, avec leur imbrication et temps d'utilisation\n",
    "* Les onglets en bas permettent de visualiser d'autres éléments, notamment le graphe des appels pour la fonction sélectionnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse mémoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module **sys** de Python propose une fonction `getsizeof` qui retourne l'occupation mémoire d'une variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.getsizeof(0))  # size is provided in bytes\n",
    "print(sys.getsizeof(2**800))\n",
    "print(sys.getsizeof([]))\n",
    "print(sys.getsizeof([0] * 10**6))  # a list containing 1 milion of zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_range(start, stop, step=1):\n",
    "    \"\"\"\n",
    "    Reproduit une version simple de la fonction *range* de Python 2\n",
    "    \n",
    "    Exemples:\n",
    "    \n",
    "    >>> my_range(10, 20, 2)\n",
    "    [10, 12, 14, 16, 18]\n",
    "    \n",
    "    >>> my_range(20, 10, -2)\n",
    "    [20, 18, 16, 14, 12]\n",
    "    \n",
    "    >>> my_range(10, 20, -1)\n",
    "    []\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    while start * step < stop * step:\n",
    "        result.append(start)\n",
    "        start += step\n",
    "        \n",
    "    return result\n",
    "\n",
    "a = my_range(0, 10**6)\n",
    "print(sys.getsizeof(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour aller un peu plus loin, la librairie [**Memory profiler**](https://pypi.org/project/memory-profiler/) permet de calculer l'occupation mémoire de chaque ligne de code des fonctions de votre programme, un peu comme **line profiler**.\n",
    "\n",
    "```bash\n",
    "bash ou C:> pip install memory_profiler\n",
    "Ou\n",
    "bash ou C:> conda install memory_profiler\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file my_range_memory.py\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "@profile(precision=4)\n",
    "def my_range(start, stop, step=1):\n",
    "    \"\"\"\n",
    "    Reproduire une version simple de la fonction *range* de Python 2\n",
    "    \n",
    "    Exemples:\n",
    "    \n",
    "    >>> my_range(10, 20, 2)\n",
    "    [10, 12, 14, 16, 18]\n",
    "    \n",
    "    >>> my_range(20, 10, -2)\n",
    "    [20, 18, 16, 14, 12]\n",
    "    \n",
    "    >>> my_range(10, 20, -1)\n",
    "    []\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    while start * step < stop * step:\n",
    "        result.append(start)\n",
    "        start += step\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    my_range(0, 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python my_range_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici la démonstration n'est pas très concluante car la ligne *append* est répétée et l'incrément correspond à celui de la dernière exécution, mais on observe tout de même que la mémoire a doublé entre le début et la fin de la fonction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce sera plus démonstratif avec cet autre exemple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file my_range_memory.py\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "def my_range(start, stop, step=1):\n",
    "    \"\"\"\n",
    "    Reproduire une version simple de la fonction *range* de Python 2\n",
    "    \n",
    "    Exemples:\n",
    "    \n",
    "    >>> my_range(10, 20, 2)\n",
    "    [10, 12, 14, 16, 18]\n",
    "    \n",
    "    >>> my_range(20, 10, -2)\n",
    "    [20, 18, 16, 14, 12]\n",
    "    \n",
    "    >>> my_range(10, 20, -1)\n",
    "    []\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    while start * step < stop * step:\n",
    "        result.append(start)\n",
    "        start += step\n",
    "        \n",
    "    return result\n",
    "\n",
    "@profile\n",
    "def memtest():\n",
    "    a = my_range(0, 10**6)\n",
    "    b = my_range(0, 10**6)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   memtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python my_range_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est intéressant de voir que la mémoire a augmenté de 39Mib lors de la création de la variable `a`, alors que la taille de `my_range` pour le premier million d'entiers est de 8mo environ, comme vu précédemment. En fait, la fonction *append* alloue plus qu'un élément à chaque appel: si la liste n'a plus de place, le tableau est incrémenté de 10 éléments la première fois que la limite de stockage est atteinte, puis 100, puis 1000 etc... \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie permet aussi de visualiser l'encombrement mémoire de votre programme au fil du temps, en permettant d'inclure les différents sous-process si besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mprof run my_range_memory.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "bash ou c:> mprof plot\n",
    "```\n",
    "\n",
    "La librairie **matplotlib** doit être installée pour cela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mprof plot](mprof_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter memit et mprun\n",
    "\n",
    "La librairie **memory_profiler** propose aussi des mots clefs magiques pour **Jupyter**:\n",
    "\n",
    "* *%memit* : Mesure l'occupation mémoire d'une instruction ou cellule\n",
    "* *%mprun* : Mesure l'encombrement mémoire d'un fonction ligne par ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit my_range(0, 10**6)\n",
    "%memit range(0, 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_range_memory import my_range\n",
    "%mprun -f my_range my_range(0, 10**4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisations\n",
    "\n",
    "Maintenant que nous avons découvert différents outils de profiling, nous allons étudier quelques optimisations possibles et classiques en Python\n",
    "\n",
    "![super hero](superhero.jpg \"Pixabay https://pixabay.com/illustrations/superhero-girl-speed-runner-534120/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padovan\n",
    "\n",
    "Notre implémentation de la suite de padovan est particulièrement lente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padovan(n):\n",
    "    return 1 if n <= 2 else padovan(n - 3) + padovan(n - 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**timeit** nous montre que la fonction est lente: près de 2 secondes pour padovan de 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 1 padovan(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cProfile** nous permet de comprendre pourquoi : padovan(60) appelle 30 693 571 fois la fonction !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import Profile\n",
    "pr = Profile()\n",
    "pr.enable()\n",
    "padovan(60)\n",
    "pr.disable()\n",
    "pr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GraphMe**, **pycalgraph2** ou encore **pyprof2calltree** nous permettent de mieux visualiser les différents appels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycallgraph2 import PyCallGraph\n",
    "from pycallgraph2.output import GraphvizOutput\n",
    "\n",
    "gfx = GraphvizOutput()\n",
    "gfx.output_file = 'pycallgraph_padovan_50.png'\n",
    "\n",
    "with PyCallGraph(output=gfx):\n",
    "    padovan(50) # With 60 it is too long to wait for..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pado 50](pycallgraph_padovan_50.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, l'implémentation récursive est élégante mais pas du tout optimisée. Chaque appel en génère 2 autres et ainsi de suite. C'est exponentiel comme nous l'avons déjà vu.\n",
    "\n",
    "Il y a différentes manières d'optimiser cette fonction :\n",
    "\n",
    "* Eviter la récursivité avec une version itérative\n",
    "* Eviter de recalculer les valeurs déjà calculées avec un mécanisme de cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padovan(n):\n",
    "    \"\"\"\n",
    "    Le site web de Python montre une belle implémentation de Fibonacci sur sa page d'accueil\n",
    "    Voici une adaptation pour Padovan\n",
    "    \"\"\"\n",
    "    a, b, c = 1, 1, 1\n",
    "    \n",
    "    ind = 0\n",
    "\n",
    "    while ind != n:\n",
    "        a, b, c = b, c, a + b\n",
    "        ind += 1\n",
    "        \n",
    "    return a\n",
    "\n",
    "for n, value in enumerate([1, 1, 1, 2, 2, 3, 4, 5, 7, 9, 12]):\n",
    "    r = padovan(n)\n",
    "    assert r == value, f'Mauvaise valeur pour n={n} valeur attendue:{value} valeur obtenue:{r}'\n",
    "    \n",
    "%timeit padovan(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais toutes les fonctions ne peuvent pas se ré-écrire aussi facilement. Dans ce cas, lorsqu'une fonction déterministe demande un long temps de calcul, il est possible de mettre en cache les valeurs déjà calculées pour ne pas les recalculer aux appels suivants si la fonction est rappelée avec les mêmes paramètres.\n",
    "\n",
    "Nous entendons ici par fonction déterministe une fonction qui retourne toujours la même valeur si on l'appelle avec les mêmes paramètres. \n",
    "\n",
    "* Le calcul du nième nombre premier sera une fonction déterministe\n",
    "* Le calcul de la nième décimale de PI en sera une autre\n",
    "* En général toutes les fonctions mathématiques du type $y = f(x)$ sont de telles fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une nouvelle version de la suite de Padovan avec cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_pado = {0 : 1, 1 : 1, 2 : 1}\n",
    "\n",
    "def padovan(n):\n",
    "        \n",
    "    # vérifier si n est une clé de cache, sinon calculer n et la stocker dans le cache\n",
    "    if n not in cache_pado:\n",
    "        cache_pado[n] = padovan(n - 3) + padovan(n - 2)\n",
    "        \n",
    "    return cache_pado[n]\n",
    "\n",
    "%timeit -n 1 -r 1 padovan(60)  # Le premier appel est un peu plus long \n",
    "                               # parce que les 60 premières valeurs doivent être calculées\n",
    "%timeit padovan(60)  # déjà en cache, donc très rapide\n",
    "print(cache_pado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette implémentation est sympathique mais a l'inconvénient de nécessiter une variable globale `cache_pado`. Ce n'est pas très efficace ni élégant. On peut rendre cela un brin plus propre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padovan(n):\n",
    "        \n",
    "    # vérifier si n est une clé de cache, sinon calculer n et la stocker dans le cache\n",
    "    if n not in padovan.cache:\n",
    "        padovan.cache[n] = padovan(n - 3) + padovan(n - 2)\n",
    "        \n",
    "    return padovan.cache[n]\n",
    "\n",
    "padovan.cache = {0 : 1, 1 : 1, 2 : 1}\n",
    "%timeit -n 1 -r 1 padovan(60)  # Le premier appel est un peu plus long \n",
    "                                 # parce que les 60 premières valeurs doivent être calculées\n",
    "%timeit padovan(60)  # déjà en cache, donc très rapide\n",
    "\n",
    "print(padovan.cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et enfin, on peut le rendre générique avec un décorateur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import sleep\n",
    "\n",
    "def cache(func_to_patch):\n",
    "    \n",
    "    cache = {}  # variable locale capturée à l'aide d'une [Fermeture](https://fr.wikipedia.org/wiki/Fermeture_(informatique))\n",
    "                # Nous pourrions aussi garder le cache comme attribut de patch, tout comme avant\n",
    "    def patch(*args):\n",
    "        \"\"\"patch will replace func_to_patch but keep reference to original func_to_patch\"\"\"\n",
    "        if args not in cache:\n",
    "            cache[args] = func_to_patch(*args)  # Appeler la fonction d'origine\n",
    "            \n",
    "        return cache[args]\n",
    "    \n",
    "    return patch\n",
    "\n",
    "\n",
    "@cache\n",
    "def padovan(n):\n",
    "    \"\"\"\n",
    "    en écrivant @something avant le nom d'une fonction, python crée la fonction, puis l'exécute\n",
    "\n",
    "    function = something(function)\n",
    "    \n",
    "    ici, cela signifie que\n",
    "    \n",
    "    padovan = cache(padovan)\n",
    "    \n",
    "    Ainsi padovan est remplacé par le résultat du cache : la fonction patch\n",
    "    \n",
    "    \"\"\"\n",
    "    return 1 if n <= 2 else padovan(n - 3) + padovan(n - 2)\n",
    "    \n",
    "%timeit -n 1 -r 1 padovan(60)\n",
    "%timeit padovan(60)\n",
    "\n",
    "@cache\n",
    "def cube(n):\n",
    "    sleep(1)\n",
    "    return n ** 3\n",
    "\n",
    "%timeit -n 1 -r 1 cube(60)\n",
    "%timeit cube(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un décorateur peut aussi s'écrire en version *objet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "    \n",
    "    def __init__(self, func_to_patch):\n",
    "        self.func = func_to_patch\n",
    "        self.cache = {}\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        \"\"\"\n",
    "        Quand vous écrivez :\n",
    "        a = Cache(func)\n",
    "        a(x, y, z) # here, python exécute Cache.__call__(a, x, y, z)\n",
    "        \"\"\"\n",
    "        if args not in self.cache:\n",
    "            self.cache[args] = self.func(*args)\n",
    "            \n",
    "        return self.cache[args]\n",
    "        \n",
    "@Cache\n",
    "def padovan(n):\n",
    "    \"\"\"\n",
    "    Ici Python exécute\n",
    "    \n",
    "    padovan = Cache(padovan)\n",
    "    \n",
    "    Donc, padovan est une instance de Cache\n",
    "    et padovan.func = <l'ancien padovan, le code qui suit>\n",
    "    \"\"\"\n",
    "    return 1 if n <= 2 else padovan(n - 3) + padovan(n - 2)\n",
    "    \n",
    "    \n",
    "%timeit -n 1 -r 1 padovan(60)  # Cache.__call__(padovan, 60)\n",
    "%timeit padovan(60)\n",
    "padovan.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, Python propose déjà un tel décorateur dans le module **functools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def padovan(n):\n",
    "    return 1 if n <= 2 else padovan(n - 3) + padovan(n - 2)\n",
    "    \n",
    "    \n",
    "%timeit -n 1 -r 1 padovan(60)  # Cache.__call__(padovan, 60)\n",
    "%timeit padovan(60)\n",
    "padovan.cache_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersection\n",
    "\n",
    "> Le plus important dans un programme ce n'est pas l'algorithme, mais la structure de données\n",
    "\n",
    "*Peut-être [Donald Knuth](https://fr.wikipedia.org/wiki/Donald_Knuth), mais je n'ai pas réussi à retrouver la citation exacte*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for e1 in l1:\n",
    "        for e2 in l2:\n",
    "            if e1 == e2:\n",
    "                result.append(e1)\n",
    "                \n",
    "    return result\n",
    "\n",
    "\n",
    "%timeit intersection(range(1, 2000), range(1000, 3000))\n",
    "%timeit -n 1 -r 1 intersection(range(1, 20000), range(10000, 30000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**timeit** nous montre que lorsque l'on augmente par 10 le nombre d'éléments, le temps d'exécution passe de 0.093 sec à 9.29 sec.  \n",
    "Il est multiplié par 100 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for e1 in l1:  # Si M élements dans l1\n",
    "        for e2 in l2:  # Si N élements dans l2\n",
    "            if e1 == e2:  # Si test est exécuté M*N fois\n",
    "                          # Si M=N, la complexité est N*N = N**2 opérations \n",
    "                result.append(e1)\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En effet, s'il y a `M` éléments dans l1 et `N` dans l2 le test *if* est exécuté `M*N` fois.  Si `M` est égal à `N`, le nombre d'opérations pour réaliser l'intersection est égal à `N*N` soit `N**2`.  \n",
    "\n",
    "On dit que la complexité de l'algorithme est de l'ordre de `N**2`, ce qui se note $O(N^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f intersection intersection(range(1, 2001), range(1000, 3000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 1.63322 s\n",
    "File: <ipython-input-1-2de2675686e0>\n",
    "Function: intersection at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           def intersection(l1, l2):\n",
    "     2                                               \n",
    "     3         1          1.0      1.0      0.0      result = []\n",
    "     4                                               \n",
    "     5      2001        375.0      0.2      0.0      for e1 in l1:\n",
    "     6   4002000     805409.0      0.2     49.3          for e2 in l2:\n",
    "     7   4000000     827190.0      0.2     50.6              if e1 == e2:\n",
    "     8      1001        248.0      0.2      0.0                  result.append(e1)\n",
    "     9                                                           \n",
    "    10         1          0.0      0.0      0.0      return result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, l'on observe bien que le test *if* est exécuté `2000 * 2000` fois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe différentes manières d'optimiser cet algorithme.   \n",
    "Commençons par le plus simple: il est inutile de continuer de chercher `e1` dans `l2` s'il a déjà été trouvé. Un *break* après le *append* nous fera gagner quelques itérations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for e1 in l1:  \n",
    "        for e2 in l2:  \n",
    "            if e1 == e2:  \n",
    "                result.append(e1)\n",
    "                break\n",
    "                \n",
    "    return result\n",
    "\n",
    "%timeit intersection(range(1, 2000), range(1000, 3000))\n",
    "%timeit -n 1 -r 1 intersection(range(1, 20000), range(10000, 30000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'optimisation n'est pas encore fabuleuse mais le temps a diminué de près de 50%. La complexité reste toujours de l'ordre du carré.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons encore gagner un peu de temps:  Python dispose de son propre opérateur *in* qui permet de vérifier si un élément existe dans une liste. Ceci nous permet d'économiser une boucle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for e1 in l1: # Si M éléments dans l1\n",
    "        if e1 in l2: # M tests sont exécutés\n",
    "                     # Est-ce-que la complexité reste la même?\n",
    "            result.append(e1)\n",
    "                \n",
    "    return result\n",
    "\n",
    "%timeit intersection(list(range(1, 2000)), list(range(1000, 3000)))\n",
    "%timeit -n 1 -r 1 intersection(list(range(1, 20000)), list(range(10000, 30000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous venons de réduire le temps d'un facteur 3, mais la mesure du temps d'exécution montre que la complexité reste de l'ordre du carré du nombre d'éléments: Si le nombre d'éléments augmente d'un facteur `x10`, la durée augmente d'un facteur `x100`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fait l'opérateur *in* masque une boucle imbriquée, il compare `e1` à tous les éléments de `l2` et s'arrête lorsqu'il trouve une correspondance ou s'il arrive à la fin de `l2`.  Cela reste plus rapide car cet opérateur est implémenté en langage C  et donc plus performant qu'une boucle Python.  \n",
    "\n",
    "Cette complexité est confirmée par ce [tableau des complexités des instructions du wiki Python](https://wiki.python.org/moin/TimeComplexity)  \n",
    "\n",
    "L'opérateur `in` a une complexité de $O(N)$, autrement dit, si la liste possède `N` éléments, `N` opérations seront exécutées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce tableau montre aussi que les types *set* et *dict* possèdent un opérateur *in* ayant une complexité d'ordre 1, autrement dit, si l'objet *set/dict* possède N éléments, l'opérateur *in* ne demandera qu'une instruction !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous avez été observateurs, vous aurez remarqué que le code a été quelque peu transformé dans l'exemple précédent: la fonction `intersection` a reçu des listes et non des objets `range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit intersection(range(1, 2000), range(1000, 3000))\n",
    "%timeit -n 1 -r 1 intersection(range(1, 20000), range(10000, 30000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En effet, en Python 2, la fonction `range` retourne une liste, mais en Python 3 cette fonction est un type à part entière qui implémente son propre opérateur *in* qui calcule si les éléments sont présents ou non. De ce fait il est extrêmement rapide et sa complexité est d'ordre $O(1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayons avec cette première implémentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    \n",
    "    result = []\n",
    "    # Nous créons un dictionnaire ayant l1 items comme clés\n",
    "    d1 = {}\n",
    "    for e1 in l1:\n",
    "        d1[e1] = None  # Nous ne nous soucions pas des valeurs, seules les clés sont importantes ici.\n",
    "\n",
    "    # Peut aussi s'écrire comme ceci:\n",
    "    # d1 = { e1 : None for e1 in l1 }\n",
    "    # d1 = dict.fromkeys(l1)\n",
    "\n",
    "    # Vérifions maintenant si les éléments de l2 sont des clés de d1\n",
    "    for e2 in l2:\n",
    "        if e2 in d1:\n",
    "            result.append(e2)\n",
    "            \n",
    "    return result\n",
    "\n",
    "%timeit intersection(range(1, 2000), range(1000, 3000))\n",
    "%timeit -n 1 -r 1 intersection(range(1, 20000), range(10000, 30000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons ici 2 choses:\n",
    "\n",
    "* La durée d'exécution est nettement plus courte\n",
    "* La complexité semble linéaire : si le nombre d'éléments est multiplié par 10, le temps l'est aussi, enfin, à peine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    \n",
    "    result = []\n",
    "    # Nous créons un dictionnaire ayant l1 items comme clés\n",
    "    d1 = {}\n",
    "    for e1 in l1:\n",
    "        d1[e1] = None  # Si M postes en l1, M affectations sont exécutées\n",
    "\n",
    "    # Vérifions maintenant si les éléments de l2 sont des clés de d1\n",
    "    for e2 in l2:\n",
    "        if e2 in d1:  # Si N points en l2, N tests sont exécutés\n",
    "                      # Mais l'opérateur *in* calcule si e2 appartient aux touches d1, il ne le compare pas.\n",
    "                      # à chaque touche, donc c'est très rapide !\n",
    "            result.append(e2)\n",
    "            \n",
    "    # Enfin, nous avons N+M opérations, si N=M, 2N opérations, la complexité est O(2N)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La création du dictionnaire requiert `M` affectations si `l1` possède `M` éléments.  \n",
    "La recherche de `e2` dans les clefs de `d1` est exécutée `N` fois si `l2` possède `N` éléments.  \n",
    "Comme la complexité de l'opérateur `in` du dictionnaire est $O(1)$, il n'y a pas de parcours masqué et au final nous avons `M+N` opérations, soit `2N` opérations si `M=N`.  \n",
    "La complexité est devenue linéaire grâce à une structure de données performante.  \n",
    "\n",
    "Pourquoi l'opérateur `in` dans un dictionnaire est aussi efficace ? Parce qu'il utilise une structure de données très adaptée et l'algorithme [Open Adressing](https://en.wikipedia.org/wiki/Open_addressing) pour rechercher ses clefs.  \n",
    "\n",
    "En quelque mots, un dictionnaire est un tableau indicé, où à un indice donné sont stockés et la clef et sa valeur.  Quand on veut accéder à une clef, une fonction de hachage calcule l'indice de cette clef via l'algorithme précédent.  Si l'indice retourné est inférieur au nombre d'éléments du tableau : la clef existe, sinon c'est une nouvelle clef.  \n",
    "\n",
    "Si vous êtes curieux, cet excellent article de *Laurent Luce* explique plus en détails [l'implémentation des dictionnaires](https://www.laurentluce.com/posts/python-dictionary-implementation/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice nous avons utilisé un dictionnaire ne possédant que des clefs, les valeurs n'ont pas été utilisées.  \n",
    "Ce type de dictionnaire est appelé un *set* en Python et constitue un type à part entière avec de véritables opérations ensemblistes.  \n",
    "\n",
    "* Un *set* ne peut avoir qu'une seule occurrence d'une même valeur\n",
    "* Un *set* ne peut contenir que des types non modifiables (non mutable)\n",
    "\n",
    "Son opérateur d'intersection `&` est implémenté grosso-modo comme dans l'exemple précédent avec le dictionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    s1 = set(l1)\n",
    "    s2 = set(l2)\n",
    "    \n",
    "    return s1 & s2\n",
    "\n",
    "%timeit intersection(range(1, 2000), range(1000, 3000))\n",
    "%timeit -n 1 -r 1 intersection(range(1, 20000), range(10000, 30000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois nous explosons tous les records.  \n",
    "\n",
    "Il y a encore d'autres manières de traiter cet exercice.  \n",
    "(Voici une solution qui m'a été soufflée par l'un des participants d'une formation Python que j'ai dispensée)  \n",
    "\n",
    "En supposant que les listes soient triées, on peut diminuer le nombre d'opérations à *au mieux* `max( [ len(l1), len(l2) ] )` opérations et *au pire* `N+M` opérations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    \"\"\"Suppose that l1 and l2 are ordered\"\"\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    ind1, ind2 = 0, 0\n",
    "    len1, len2 = len(l1), len(l2)\n",
    "    \n",
    "    while ind1 < len1 and ind2 < len2:\n",
    "        \n",
    "        e1 = l1[ind1]\n",
    "        e2 = l2[ind2]\n",
    "        \n",
    "        if e1 == e2:  # résultat trouvé\n",
    "            result.append(e1)\n",
    "            # incrémenter les deux indices\n",
    "            ind1 += 1\n",
    "            ind2 += 1\n",
    "        elif e1 < e2:\n",
    "            # e1 est inférieur à e2, rechercher l'élément suivant dans l1\n",
    "            ind1 += 1\n",
    "        else:\n",
    "            ind2 += 1\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "%timeit intersection(list(range(1, 2000)), list(range(1000, 3000)))\n",
    "%timeit -n 1 -r 1 intersection(list(range(1, 20000)), list(range(10000, 30000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut s'affranchir de la supposition sur le tri en triant les listes en début de fonction.  \n",
    "Les performances restent très bonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(l1, l2):\n",
    "    \"\"\"l1 et l1 sont triés après la fonction : dangereux\"\"\"\n",
    "    \n",
    "    l1.sort()\n",
    "    l2.sort()    \n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    ind1, ind2 = 0, 0\n",
    "    len1, len2 = len(l1), len(l2)\n",
    "    \n",
    "    while ind1 < len1 and ind2 < len2:\n",
    "        \n",
    "        e1 = l1[ind1]\n",
    "        e2 = l2[ind2]\n",
    "        \n",
    "        if e1 == e2:  # résultat trouvé\n",
    "            result.append(e1)\n",
    "            # incrémenter les deux indices\n",
    "            ind1 += 1\n",
    "            ind2 += 1\n",
    "        elif e1 < e2:\n",
    "            # e1 est inférieur à e2, rechercher l'élément suivant dans l1\n",
    "            ind1 += 1\n",
    "        else:\n",
    "            ind2 += 1\n",
    "            \n",
    "    return result\n",
    "\n",
    "%timeit intersection(list(range(1, 2000)), list(range(1000, 3000)))\n",
    "%timeit -n 1 -r 1 intersection(list(range(1, 20000)), list(range(10000, 30000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python propose de nombreux autres [structures de données très intéressantes qui peuvent vous aider à optimiser/simplifier vos algorithmes](https://docs.python.org/3/library/datatypes.html).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour creuser le sujet voici quelques ouvrages :\n",
    "\n",
    "* Le livre [Problem Solving with Algorithms and Data Structures using Python](https://runestone.academy/runestone/books/published/pythonds/index.html) en *License Creative Commons*.  \n",
    "* Le site PacktPublishing propose aussi plusieurs livre sur le theme [Python Data structures and algorithms](https://subscription.packtpub.com/search?query=python%20data%20structure&released=Available)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons vu que notre fonction `my_range` n'est pas intéressante dans sa version actuelle:  elle retourne une liste d'éléments.  \n",
    "Si vous voulez l'utiliser pour compter de 1 à 1 million dans une boucle *for*, vous allez allouer 1 million d'entiers :\n",
    "\n",
    "* Cela demandera de la mémoire\n",
    "* Cela prend du temps pour l'allocation de cette mémoire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est la réflexion que se sont faits les développeurs de Python 3. En Python 2, beaucoup de fonctions qui retournaient de véritables listes, comme `range`, `filter`, `map`, `zip` sont devenues des générateurs/itérateurs ou types à part entière pour contourner ce problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python2 -c \"a = range(10); print type(a), a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -c \"a = range(10); print(type(a), a)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des fonctions qui retournent de grandes listes de données méritent probablement d'être ré-écrites sous forme de générateur.\n",
    "\n",
    "Un générateur est une fonction qui au lieu de retourner une liste de valeurs, retourne la première valeur au premier appel, puis la seconde au second appel et ainsi de suite.\n",
    "\n",
    "Pour permettre ce comportement votre fonction ne doit pas retourner de valeur avec le mot clef `return` mais avec un nouveau mot clef **`yield`** qui retourne une valeur et met la fonction en pause. \n",
    "\n",
    "A l'appel suivant, la fonction reprend juste après l'instruction `yield`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour transformer une fonction en générateur, il y a 3 étapes à réaliser:\n",
    "\n",
    "1. Supprimer la création de la liste contenant le résultat, généralement `result = []` \n",
    "2. Remplacer `result.append(value)` par `yield value`\n",
    "3. Finalement, supprimer l'instruction `return result` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nous reprenons la version initiale de `my_range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_range(start, stop, step=1):\n",
    "    \"\"\"\n",
    "    Reproduire une version simple de la fonction *range* de Python 2\n",
    "    \n",
    "    Exemples:\n",
    "    \n",
    "    >>> my_range(10, 20, 2)\n",
    "    [10, 12, 14, 16, 18]\n",
    "    \n",
    "    >>> my_range(20, 10, -2)\n",
    "    [20, 18, 16, 14, 12]\n",
    "    \n",
    "    >>> my_range(10, 20, -1)\n",
    "    []\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    while start * step < stop * step:\n",
    "        result.append(start)\n",
    "        start += step\n",
    "        \n",
    "    return result\n",
    "\n",
    "for a in my_range(5, -1, -1):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa version générateur donnera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_range_gen(start, stop, step=1):\n",
    "    \"\"\"\n",
    "    version générateur de my_range\n",
    "    \"\"\"\n",
    "    # result = []  # no more requires\n",
    "    \n",
    "    while start * step < stop * step:\n",
    "        # result.append(start)\n",
    "        yield start\n",
    "        start += step\n",
    "        \n",
    "    # return result  # no more required\n",
    "\n",
    "for a in my_range_gen(5, -1, -1):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est le même, mais l'encombrement mémoire est nettement moindre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.getsizeof(my_range(0, 10**6)), sys.getsizeof(my_range_gen(0, 10**6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux comprendre comment cela se passe, ajoutons une trace dans la version générateur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_range_gen(start, stop, step=1):\n",
    "    \"\"\"\n",
    "    version générateur de my_range\n",
    "    \"\"\"\n",
    "    while start * step < stop * step:\n",
    "        print(\"Avant yield, start=\", start)\n",
    "        yield start\n",
    "        print(\"Après yield, start=\", start)\n",
    "        start += step\n",
    "\n",
    "        \n",
    "for a in my_range_gen(3, -1, -1):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au premier appel de la fonction par le *for* la fonction s'exécute et affiche `Before yield, start= 3` puis retourne `3` et se met en pause.  \n",
    "La boucle *for* reprend la main, affiche la valeur `3` puis rappelle la fonction, qui se réveille et continue juste où elle s'était arrêtée, c'est-à-dire après le mot clef `yield` et affiche `After yield, start= 3`  \n",
    "Et ainsi de suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui peut surprendre c'est que cela fonctionne aussi avec des boucles imbriquées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_range_gen(start, stop, step=1):\n",
    "    \"\"\"\n",
    "    version générateur de my_range\n",
    "    \"\"\"\n",
    "    \n",
    "    while start * step < stop * step:\n",
    "        yield start\n",
    "        start += step\n",
    "        \n",
    "\n",
    "for a in my_range_gen(3, -1, -1):\n",
    "    print(a)\n",
    "    for b in my_range_gen(10, 20, 5):\n",
    "        print(\"  \", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment la fonction fait-elle pour ne pas se mélanger les pinceaux entre les appels imbriqués, les valeurs de `start`, `stop` et les incréments ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En fait notre première explication de la mécanique des générateurs a été quelque peu simplifiée pour faciliter la compréhension globale.\n",
    "\n",
    "* Quand une fonction possède le mot clef `yield` Python la transforme\n",
    "* Lors de son appel elle ne s'exécute pas mais retourne une copie de la fonction originale avec ses paramètres\n",
    "* Pour la démarrer il faut utiliser la fonction `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_range_gen(start, stop, step=1):\n",
    "    \"\"\"\n",
    "    version générateur de my_range\n",
    "    \"\"\"\n",
    "    print(\"valeurs reçues\", start, stop, step)\n",
    "    \n",
    "    while start * step < stop * step:\n",
    "        print(\"Avant yield, start=\", start)\n",
    "        yield start\n",
    "        print(\"Après yield, start=\", start)\n",
    "        start += step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appelons la fonction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = my_range_gen(10, 14, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rien ne s'exécute. Mais une copie de la fonction est retournée dans l'objet *g* qui est ce que l'on appelle un générateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il convient de démarrer `g` avec la fonction `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = next(g)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons demander la valeur suivante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = next(g)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quand il n'y a plus rien à retourner, un nouvel appel à `next` génère une exception **`StopIteration`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "v = next(g)\n",
    "print(v)\n",
    "```\n",
    "\n",
    "```\n",
    "After yield, start= 12\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "StopIteration                             Traceback (most recent call last)\n",
    "<ipython-input-103-142a79cb4c53> in <module>\n",
    "----> 1 v = next(g)\n",
    "      2 print(v)\n",
    "\n",
    "StopIteration: \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans une boucle *for* ceci est transparent, c'est la boucle qui exécute de manière transparente les appels à `next` et intercepte l'exception **`StopIteration`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un générateur c'est bête, un itérateur c'est mieux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y aurait beaucoup de choses à dire sur les générateurs. Nous aborderons ici uniquement quelques unes de ses limitations afin de savoir jusqu'où l'on peut aller et comment faire mieux avec les *itérateurs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_range_gen(start, stop, step=1):\n",
    "    \n",
    "    while start * step < stop * step:\n",
    "        yield start\n",
    "        start += step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un générateur ne se consomme qu'une fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = range(0, 3)\n",
    "g = my_range_gen(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for v in r:\n",
    "    print(v)\n",
    "    \n",
    "for v in r:  # range est intelligent et permet des itérations multiples\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for v in g:\n",
    "    print(v)\n",
    "    \n",
    "for v in g:  # fin de la fonction déjà atteint\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un générateur ne garantit pas un bon usage de *in*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_range_gen(start, stop, step=1):\n",
    "    \n",
    "    while start * step < stop * step:\n",
    "        print(\"start=\", start)\n",
    "        yield start\n",
    "        start += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = range(0, 3)\n",
    "g = my_range_gen(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 in r, 10 in r, 2 in r, 10 in r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 in g, 10 in g, 2 in g, 10 in g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'opérateur *in* fonctionne avec un générateur, mais il itère sur les éléments pour trouver les valeurs demandées.  Quand il cherche `10` qu'il ne trouve pas, il consomme toute la liste. Si l'on redemande `2`, il retournera *False* car la liste a été consommée entièrement pour `10` et il ne se consomme qu'une fois...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ils ont aussi d'autres limites, comme l'absence des opérateurs `[]` pour lire un élément ou encore de la fonction `len`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour contourner ces limites vous pouvez implémenter votre générateur sous forme d'une classe.  \n",
    "\n",
    "Pour cela 2 méthodes spéciales sont requises:\n",
    "\n",
    "* `__iter__` qui retourne l'itérateur, en général l'instance elle-même sauf si vous voulez implémenter des itérateurs *à la Java*\n",
    "* `__next__` qui retourne la valeur suivante et génère **`StopIteration`** s'il n'y a plus rien à retourner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRange:\n",
    "    \n",
    "    def __init__(self, start, stop, step=1):\n",
    "        self.start = start\n",
    "        self.stop = stop\n",
    "        self.step = step\n",
    "        self.current = start\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        \n",
    "        # conserve la valeur actuelle à retourner\n",
    "        cur = self.current\n",
    "        \n",
    "        # lève une exception si la fin est atteinte\n",
    "        if cur * self.step >= self.stop * self.step:\n",
    "            raise StopIteration()\n",
    "        \n",
    "        # incrémente current pour le prochain appel\n",
    "        self.current += self.step\n",
    "        \n",
    "        return cur\n",
    "    \n",
    "for v in MyRange(3, -1, -1):\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice\n",
    "\n",
    "Modifiez la classe pour que votre générateur implémente correctement l'opérateur *in* et puisse être utilisé de multiples fois.  Pour l'opérateur *in* implémentez la méthode [`__contains__`](https://docs.python.org/3/reference/datamodel.html#object.__contains__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class MyRange:\n",
    "    \n",
    "    # votre code ici\n",
    "    pass\n",
    "\n",
    "    \n",
    "    \n",
    "g = MyRange(3, -1, -1)\n",
    "assert list(g) == [3, 2, 1, 0]\n",
    "assert list(g) == [3, 2, 1, 0]  # Ne doit pas être vide à la seconde utilisation\n",
    "print(\"Seconde utilisation implémentée!\")\n",
    "\n",
    "assert (2 in g, 10 in g, 2 in g) == (True, False, True)\n",
    "print(\"in correctement implémenté !\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button data-toggle=\"collapse\" data-target=\"#MyRange\" class='btn btn-primary'>Solution</button>\n",
    "<div id=\"MyRange\" class=\"collapse\">\n",
    "\n",
    "```python\n",
    "class MyRange:\n",
    "    \n",
    "    def __init__(self, start, stop, step=1):\n",
    "        self.start = start\n",
    "        self.stop = stop\n",
    "        self.step = step\n",
    "        self.current = start\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        \n",
    "        # conserve la valeur actuelle à retourner\n",
    "        cur = self.current\n",
    "        \n",
    "        # lève une exception si la fin est atteinte\n",
    "        if cur * self.step >= self.stop * self.step:\n",
    "            self.current = self.start  # réinitialise current pour la prochaine itération\n",
    "            raise StopIteration()\n",
    "        \n",
    "        # incrémente current pour le prochain appel\n",
    "        self.current += self.step\n",
    "        \n",
    "        return cur\n",
    "    \n",
    "    def __contains__(self, value):\n",
    "        \n",
    "        # Vérifie s'il y a un intervalle extérieur\n",
    "        if value * self.step < self.start * self.step:\n",
    "            return False\n",
    "\n",
    "        if value * self.step >= self.stop * self.step:\n",
    "            return False\n",
    "        \n",
    "        # La valeur se situe entre le démarrage et l'arrêt.\n",
    "        return (value - self.start) % self.step == 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant utiliser la version d'`intersection` avec une seule boucle *for* et l'opérateur *in* avec votre itérateur: elle sera très efficace puisque votre version de `__contains__` calcule (si bien implémentée) si la valeur demandée existe, plutôt que de la comparer avec tous les éléments de la liste..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def intersection(l1, l2):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for e1 in l1:\n",
    "        if e1 in l2:\n",
    "            result.append(e1)\n",
    "            \n",
    "    return result\n",
    "\n",
    "%timeit intersection(MyRange(1, 2000), MyRange(1000, 3000))\n",
    "%timeit intersection(MyRange(1, 20000), MyRange(10000, 30000))\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "935 µs ± 2.02 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
    "9.52 ms ± 46.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sa complexité sera linéaire. \n",
    "\n",
    "Et évidemment, `intersection` mérite d'être ré-écrite avec un générateur !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallélisation\n",
    "\n",
    "Une fois que votre code a été optimisé du mieux que vous le pouvez, il reste encore quelques moyens pour l'accélérer : [Python offre de nombreuses librairies de parallélisation](https://wiki.python.org/moin/ParallelProcessing).\n",
    "\n",
    "Mais ce sera une autre histoire. Et puis, ce premier lien qui est déjà bien fourni est encore loin d'être à jour...\n",
    "\n",
    "D'ailleurs je file de ce pas y proposer quelques ajouts..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour aller plus loin\n",
    "\n",
    "La documentation Python de la librairie **cProfile** mérite une lecture attentive. \n",
    "\n",
    "Il existe beaucoup d'autres librairies Python pour profiler vos programmes, dont:\n",
    "\n",
    "* [**ox_profile**](https://github.com/emin63/ox_profile) : Un profileur de type statistique qui a le mérite d'offrir une intégration avec **Flask**.\n",
    "* [**statprof**](https://github.com/bos/statprof.py) : Un autre profileur statistique plus complet mais qui ne fonctionne pas sous Windows\n",
    "  \n",
    "  \n",
    "Une recherche sur Pypi en présentera beaucoup d'autres.\n",
    "\n",
    "\n",
    "Il existe aussi de nombreux tutoriels en ligne comme [How to Use Python Profilers: Learn the Basics](https://stackify.com/how-to-use-python-profilers-learn-the-basics/) qui présente d'autres librairies internes à Python comme **Trace** ou **FaultHandler**. Ce tutoriel a aussi l'avantage de présenter des outils de monitoring de performances comme [**Zipkin**](https://zipkin.io/) et [**Zaeger**](https://github.com/jaegertracing/jaeger). \n",
    "\n",
    "[**StackImpact**](https://github.com/stackimpact/stackimpact-python) est un autre outil *Application Performance Management* (APM) disposant d'une librairie Python.\n",
    "\n",
    "La série de livres [Python High Performance](https://www.packtpub.com/eu/catalogsearch/result/?q=python%20high%20performance) sur PacktPub est une très bonne source de documentation et d'approfondissement du sujet.\n",
    "\n",
    "Le livre [Mastering Python High Performance](https://www.packtpub.com/application-development/mastering-python-high-performance) est un excellent livre sur le profiling avec Python, il vous fera découvrir bien d'autres outils et vous plonge vraiment au coeur du sujet. Une lecture que les débutants et plus aguerris apprécieront !\n",
    "\n",
    "![Mastering Python High Performance - Book cover](https://www.packtpub.com/media/catalog/product/cache/e4d64343b1bc593f1c5348fe05efa4a6/9/7/9781783989300.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
